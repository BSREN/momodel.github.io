---
layout: post
title: 机器学习分享——反向传播算法推导
date: 2019-03-08 12:00
---
反向传播（英语：Backpropagation，缩写为BP）是“误差反向传播”的简称，是一种与最优化方法（如梯度下降法）结合使用的，用来训练人工神经网络的常见方法。该方法对网络中所有权重计算损失函数的梯度。这个梯度会反馈给最优化方法，用来更新权值以最小化损失函数。

很多同学在学习深度神经网络的时候，对反向传播的相关细节表示难以理解，国外有一篇技术博客,用例子进行了非常清晰的推导。我们对此进行了汉化，并提供了相关的代码。有兴趣的同学快来看看吧。

相关代码请见 http://www.momodel.cn:8899/#/explore/5b84e0098fe30b727acaa360?type=app

原文地址 https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/

假设，你有这样一个网络层

![](https://imgbed.momodel.cn/5d1483e997c32cc4678fa676.jpg)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190121185510997.png)
现在对他们赋上初值，如下图：

　　![](https://imgbed.momodel.cn/5d1483e897c32cc4678fa674.jpg)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190121185715879.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAxNTkwNw==,size_16,color_FFFFFF,t_70)
　　
　　
### 前向传播过程
　　
#### 1. 输入层---->隐含层：

![输入层-隐含层](https://img-blog.csdnimg.cn/2019012117165129.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAxNTkwNw==,size_16,color_FFFFFF,t_70)


#### 2. 隐藏层---->输出层:

![隐藏层-输出层](https://img-blog.csdnimg.cn/20190121171744947.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAxNTkwNw==,size_16,color_FFFFFF,t_70)

### 反向传播过程

接下来,就可以进行反向传播的计算了

#### 1. 计算总误差
![计算总误差](https://img-blog.csdnimg.cn/20190121172104856.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAxNTkwNw==,size_16,color_FFFFFF,t_70)


#### 2. 隐含层---->输出层的权值更新：
![权职更新](https://img-blog.csdnimg.cn/2019012117224878.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAxNTkwNw==,size_16,color_FFFFFF,t_70)
下面的图可以更直观的看清楚误差是怎样反向传播的

![](https://imgbed.momodel.cn/5d1483e797c32cc4678fa673.jpg)

我们分别计算每个式子的值：
![三个算式](https://img-blog.csdnimg.cn/20190121172439290.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAxNTkwNw==,size_16,color_FFFFFF,t_70)
最后三者相乘

![三者相乘](https://img-blog.csdnimg.cn/20190121184028433.png)
看看上面的公式,我们发现：
![公式](https://img-blog.csdnimg.cn/20190121184113143.png)
![表达式](https://img-blog.csdnimg.cn/20190121184200433.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAxNTkwNw==,size_16,color_FFFFFF,t_70)
#### 3.隐含层---->隐含层的权值更新：
![](https://img-blog.csdnimg.cn/2019012118434112.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAxNTkwNw==,size_16,color_FFFFFF,t_70)

![](https://imgbed.momodel.cn/5d1483e997c32cc4678fa675.jpg)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190121184443446.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAxNTkwNw==,size_16,color_FFFFFF,t_70)
同理,计算出
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190121184650210.png)
两者相加,得到总值


![在这里插入图片描述](https://img-blog.csdnimg.cn/20190121184827115.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190121185210557.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAxNTkwNw==,size_16,color_FFFFFF,t_70)

最后,三者相乘 
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190121185323926.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAxNTkwNw==,size_16,color_FFFFFF,t_70)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190121185411244.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAxNTkwNw==,size_16,color_FFFFFF,t_70)

这样误差反向传播法就完成了，最后我们再把更新的权值重新计算，不停地迭代.

完整代码（PC端查看）： http://www.momodel.cn:8899/#/explore/5b84e0098fe30b727acaa360?type=app

——————————————————————————————————
Mo （网址：momodel.cn ）是一个支持 Python 的人工智能建模平台，能帮助你快速开发训练并部署 AI 应用。期待你的加入。
